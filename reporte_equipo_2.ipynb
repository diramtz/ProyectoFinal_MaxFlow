{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mayo 2021\n",
    "# Algoritmo Ford - Fulkerson: Flujo Máximo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algoritmo Ford - Fulkerson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flujo máximo\n",
    "\n",
    "Los problemas de flujo máximo implican encontrar un flujo factible a través de una red con una sola fuente y un solo sumidero que sea máximo.\n",
    "\n",
    "Veamos la siguiente gráfica:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![red1](img/ford_fulkerson1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada arco está etiquetado por una capacidad la cual representa el flujo máximo que puede pasar del nodo $i$ al nodo $j$. El objetivo es encontrar la capacidad máxima de flujo que pasa del nodo origen (fuente) al nodo destino (sumidero). El flujo máximo en esta red es 23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A continuación se muestran diferentes enfoques para resolver este problema de flujo máximo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Aproximación del Algoritmo Naive Greedy (puede que no produzca un resultado óptimo o correcto)**\n",
    "\n",
    "Esta aproximación del problema del flujo máximo comienza con el flujo total cero y produce flujos con un valor cada vez mayor. La forma natural de pasar de uno a otro es enviar más flujo en algún camino de $s$ a $t$\n",
    "\n",
    "Cómo funciona el enfoque Greedy para encontrar el flujo máximo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "        E número de arista\n",
    "        f(e) flujo que se encuentra en la arista e.\n",
    "        C(e) capacidad de la arista e.\n",
    "\n",
    "\n",
    "                1) Inicializa : max_flow = 0  \n",
    "                f(e) = 0 para cada arista e en E.\n",
    "            \n",
    "                2) Encontrar un camino de s a t (mientras exista).   \n",
    "                   a) El camino existe si f(e) < C(e) para cada arista e en el camino. \n",
    "                   b) Si no se encuentra un camino, return max_flow.\n",
    "                   c) Else encontrar el valor mínimo para la ruta P\n",
    "        \n",
    "      // Nuestro flujo está limitado por el flujo que queda\n",
    "    \n",
    "      (i) flow = min(C(e)- f(e)) Para el camino P.\n",
    "             max_flow += flow\n",
    "      (ii) Para cada arista e del camino, incrementar el flujo\n",
    "             f(e) += flow\n",
    "\n",
    "                3) Return max_flow \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que la búsqueda de ruta solo necesita determinar si hay una ruta $s-t$ en el subgrafo de los bordes $e$ con $f(e) <C(e)$ por lo que no es costoso computacionalmente.\n",
    "\n",
    "Veamos elsiguiente ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![red2](img/ford_fulkerson2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe un camino de s a t $s \\rightarrow 1  \\rightarrow 2  \\rightarrow t$ con un flujo máximo de 3 unidades (la ruta se muestra en color azul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La capacidad restante está representada por los números de color verde."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el gráfico anterior notamos que no existe un camino de $s \\rightarrow t$, por lo que el flujo máximo es de 3 unidades. Pero el flujo máximo que sale del nodo origen es de 5 unidades, así como el flujo máximo que llega al nodo destino.\n",
    "\n",
    "Para superar este problema utilizamos el gráfico residual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Gráfico residual** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es extender el algoritmo mencionado anteriormente al permitir operaciones de \"deshacer\". Por ejemplo, desde el punto donde este algoritmo se atasca en la imagen de arriba, nos gustaría enrutar dos unidades más de flujo a lo largo del borde $(s, 2)$, luego hacia atrás a lo largo del borde $(1, 2)$, deshaciendo 2 de las 3 unidades enrutamos la iteración anterior, y finalmente a lo largo del borde $(1, t)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos: \n",
    "* Arco inverso: $f (e)$\n",
    "* Arco: $C (e) - f (e)$\n",
    "\n",
    "Necesitamos una forma de especificar formalmente las operaciones de \"deshacer\" permitidas. Esto motiva la siguiente definición simple pero importante, de una red residual:\n",
    "\n",
    "Dado un grafo $G$ y un flujo $f$ en él, formamos una nueva red de flujo $G_f$ que tiene el mismo conjunto de vértices de $G$ y por cada arco de $G$ se crean dos nuevos arcos.\n",
    "\n",
    "Por ejemplo, el arco $e = (1,2 )$ de $G$ lleva el flujo $f (e)$ y tiene capacidad $C (e)$ (para la imagen de arriba) genera un arco  de $G_f$ con capacidad $C (e) -f (e)$ (la capacidad restante) y un arco inverso $(2,1)$ de $G_f$ con capacidad $f (e)$ (la cantidad de flujo previamente encaminado que se puede deshacer). Ahora se tiene un camino de $s$ a $t$ con capacidad $f (e) <C (e)$ para todos los arcos.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea de utilizar gráficos residuales para flujo máximo se utiliza en el algoritmo de Ford-Fulkerson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Ford-Fulkerson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo de Ford-Fulkerson propone buscar caminos en los que se pueda aumentar el flujo, hasta que se alcance el flujo máximo. Su nombre viene dado por sus creadores, *L. R. Ford, Jr*. y *D. R. Fulkerson*\n",
    "\n",
    "Sea $G(V,E)$ un grafo, con $V$ vértices, $E$ aristas y donde por cada arista $(u,v)$, tenemos una capacidad $c(u,v)$ y un flujo $f(u,v)$. Se busca maximizar el valor del flujo desde una fuente $s$ hasta un sumidero $t$.\n",
    "\n",
    "El método inicia con $f(u,v)=0$ para toda $(u,v) \\in V)$. En cada iteración, se incrementa el flujo en $G$ mediante el resultado de una búsqueda de un camino de aumento en una red.\n",
    "\n",
    "El flujo a aumentar se debe considerar legal, es decir:\n",
    "\n",
    "   **El flujo de para toda arista $(u,v)$ no debe ser mayor que la capacidad de dicha arista. El flujo que sale de la fuente $s$ debe ser igual al que llega al sumidero $t$.**\n",
    "\n",
    "Nota: En una red con fuente $s$ y sumidero $t$ único el valor máximo que puede tomar un flujo variable es igual a la capacidad mínima que puede tomar un corte.\n",
    "\n",
    "**Red residual**\n",
    "\n",
    "Como se mencionó anteriormente, definimos una red residual $G_f(V,E)$ como la red donde la capacidad de cada una de las aristas se define como $c_f(u,v)= c(u,v) - f(u,v)$ , donde $c(u,v)$ es la capacidad de la arista y el flujo $f(u,v)$ es el flujo de la arista $(u,v)$ en el camino de aumento seleccionado.\n",
    "\n",
    "Intuitivamente, dado el grafo $G$ y un camino de aumento $c_F$, la red residual $G_f$ consiste en el grafo que representa el como cambia la capacidad de cada una de las aristas con respecto al flujo del camino de aumento $c_F$ en el grafo $G$.\n",
    "\n",
    "**Caminos de aumento**\n",
    "\n",
    "Un camino de aumento es un camino dirigido de la fuente $s$ al sumidero $t$ en $G_f$, donde la capacidad del camino de aumento es el mínimo de las capacidades de sus aristas.\n",
    "\n",
    "**Complejidad**\n",
    "\n",
    "Al agregar un camino de aumento al flujo ya establecido en el gráfico, se alcanzará el flujo máximo cuando no se puedan encontrar más caminos de aumento de flujo en el gráfico. Sin embargo, no hay certeza de que esta situación se llegue alguna vez, por lo que lo mejor que se puede garantizar es que la respuesta será correcta si el algoritmo termina. En el caso de que el algoritmo se ejecute indefinidamente, es posible que el flujo ni siquiera converja hacia el flujo máximo. Sin embargo, esta situación solo ocurre con valores de flujo irracionales. \n",
    "\n",
    "Cuando las capacidades son números enteros, el tiempo de ejecución de Ford-Fulkerson está limitado por $O(E_f)$, donde $E$ es el número de aristas en el gráfico y $f$ es el flujo máximo en el gráfico. Esto se debe a que cada ruta de aumento se puede encontrar en el tiempo $O(E)$ y aumenta el flujo en una cantidad entera de al menos $1$, con el límite superior $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pseudocódigo**\n",
    "\n",
    "      Ford-Fulkerson(G,s,t) {\n",
    "      Gf = Crear_grafo_residual(G);\n",
    "      for (cada arista (u,v) de E) {\n",
    "          f[u,v]= 0;\n",
    "      }\n",
    "      while (exista un camino p desde s a t en la red residual Gf) {\n",
    "          cf(p) = min{cf(u,v): (u,v) está sobre p};\n",
    "          for (cada arista (u,v) en p) {\n",
    "              f[u,v]= f[u,v] + cf(p);\n",
    "              f[v,u]= f[v,u] - cf(p);\n",
    "          }\n",
    "          Actualizar_grafo_residual(Gf);\n",
    "      }\n",
    "\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicaciones en la vida real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Eliminación de béisbol**\n",
    "\n",
    "En el problema de la eliminación del béisbol, hay $n$ equipos compitiendo en una liga. En una etapa específica de la temporada de la liga, $w_ii$ es el número de victorias y $ri$ es el número de juegos que quedan por jugar para el equipo $i$ y $r_{ij}$ es el número de juegos que quedan contra el equipo $j$.\n",
    "\n",
    "Un equipo es eliminado si no tiene la oportunidad de terminar la temporada en primer lugar. La tarea del problema de eliminación del béisbol es determinar qué equipos son eliminados en cada punto durante la temporada. [Schwartz, B. L](https://ui.adsabs.harvard.edu/abs/1966SIAMR...8..302S/abstract) propuso un método que reduce este problema a como un problema de flujo máximo en una red. \n",
    "\n",
    "En este método se crea una red para determinar si se elimina el equipo $k$.\n",
    "\n",
    "Sea $G = (V, E)$ una red con $s$ y $t \\in V$ la fuente y el sumidero respectivamente. Uno agrega un nodo de juego $(i, j)$ con $i <j$ al conunto de vértices y conecta cada uno de ellos desde $s$ por un borde con capacidad $r_{ij}$, que representa el número de jugadas entre estos dos equipos. También agregamos un nodo de equipo para cada equipo y conectamos cada nodo de juego $(i, j)$ con dos nodos de equipo $i$ y $j$ para asegurarnos de que uno de ellos gane. No es necesario restringir el valor de flujo en estos bordes. \n",
    "Finalmente, los arcos se hacen desde el nodo del equipo $i$ al nodo sumidero $t$ y la capacidad de $w_k + r_k – w_i $ se establece para evitar que el equipo $i$ gane más de $w_k + r_k$.\n",
    "Sea $S$ el conjunto de todos los equipos que participan en la liga y sea \n",
    "$r (S - {k}) = \\sum_{i, j \\in {S - {k}}, i <j}r_{ij}$ . En este método se afirma que el equipo $k$ no se elimina si y solo si existe un flujo de tamaño $r (S - {k})$ en la red $G$. En el artículo mencionado se demuestra que este valor de flujo es el valor de flujo máximo de $s$ a $t$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Planificación de aerolíneas**\n",
    "\n",
    "En la industria de las aerolíneas, un problema importante es la programación de las tripulaciones de vuelo. El problema de la programación de la aerolínea puede considerarse como una aplicación del flujo de red máximo extendido. La entrada de este problema es un conjunto de vuelos F que contiene la información sobre dónde y cuándo sale y llega cada vuelo. En una versión de la programación de las aerolíneas, el objetivo es producir un programa factible con un máximo de $k$ tripulaciones.\n",
    "\n",
    "Para resolver este problema, se utiliza una variación del problema de circulación llamado circulación limitada, que es la generalización de los problemas de flujo de la red, con la restricción adicional de un límite inferior en los flujos de borde.\n",
    "\n",
    "Sea $G = (V, E)$ una red con $s, t \\in V$ como los nodos fuente y sumidero. Para la fuente y el destino de cada vuelo $i$, se agregan dos nodos a $V$, el nodo $s_i$ como la fuente y el nodo $d_i$ como el nodo de destino del vuelo $i$. También se agregan los siguientes arcos a $E$:\n",
    "\n",
    "1. Un arco con capacidad 0 cuya capacidad máxima es $1$ entre $s$ y cada $s_i$. \n",
    "2. Un arco con capacidad 0 cuya capacidad máxima es $1$ para cada $d_i$ y $t$. \n",
    "3. Un arco con capacidad 1 cuya capacidad máxima es $1$ entre cada par de $s_i$ y $d_i$. \n",
    "4. Un arco con capacidad $[0,1]$ entre cada $d_i$ y $s_j$, si la fuente $s_j$ es accesible con una cantidad de tiempo y costo razonables desde el destino del vuelo $i$.\n",
    "5. Un arco con capacidad $[0, \\infty]$ entre $s$ y $t$. \n",
    "\n",
    "\n",
    "En el método mencionado, se prueba que encontrar un valor de flujo de $k$ en $G$ entre $s$ y $t$ es igual a encontrar un flujo factible para el conjunto de vuelos $F$ con un máximo de $k$ tripulaciones. \n",
    "\n",
    "Otra versión de la programación de las aerolíneas es encontrar las tripulaciones mínimas necesarias para realizar todos los vuelos. Para encontrar una respuesta a este problema, se crea un gráfico bipartito $G'= (A \\cup B, E)$ donde cada vuelo tiene una copia en el conjunto $A$ y en el conjunto $B$. Si el mismo avión puede realizar el vuelo $j$ después del vuelo $i$, $i \\in A$ está conectado a $j \\in B$. Una coincidencia en $G'$ induce un horario para $F$ y, obviamente, la máxima coincidencia bipartita en este gráfico produce un horario de línea aérea con un número mínimo de tripulaciones. La coincidencia bipartita de cardinalidad máxima es una aplicación del problema de flujo máximo. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problema de circulación-demanda**\n",
    "\n",
    "Hay algunas fábricas que producen bienes y algunos pueblos donde los bienes deben entregarse. Están conectados por una red de carreteras y cada carretera tiene una capacidad c para el máximo de mercancías que pueden fluir a través de ella. El problema es encontrar si existe una circulación que satisfaga la demanda. Este problema puede transformarse en un problema de flujo máximo si se agregan los siguintes puntos:\n",
    "\n",
    "1. Agregar un nodo de origen $s$ y arcos desde él a cada nodo de fábrica $f_i$ con capacidad $p_i$ donde $p_i$ es la tasa de producción de $f_i$ de fábrica.\n",
    "\n",
    "2. Agregar un nodo sumidero $t$ y arcos de todas las aldeas $v_i$ a $t$ con capacidad $d_i$ donde $d_i$ es la tasa de demanda de la aldea $v_i$. \n",
    "\n",
    "Sea $G = (V, E)$ esta nueva red. Existe una circulación que satisface la demanda si y solo si:\n",
    "\n",
    "$$\\text{Flujo Máximo} = \\sum_{i \\in V} d_i$$\n",
    "\n",
    "Si existe una ciculacion, la solución de flujo máximo daría la respuesta sobre la cantidad de mercancías que deben enviarse por una carretera en particular para satisfacer las demandas.\n",
    "\n",
    "El problema se puede ampliar agregando un límite inferior al flujo en algunos bordes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Segmentación de imágenes**\n",
    "\n",
    "[Kleinberg y Tardos](https://www.pearson.com/us/higher-education/program/Kleinberg-Algorithm-Design/PGM319216.html)\n",
    "presentan un algoritmo para encontrar el fondo y el primer plano en una imagen. Más precisamente, el algoritmo toma un mapa de bits como entrada modelada de la siguiente manera: $a_i \\geq 0$ es la probabilidad de que el píxel $i$ pertenezca al primer plano, $b_i \\geq 0$ en la probabilidad de que el píxel $i$ pertenezca al fondo y $p_{ij}$ es la penalización si los píxeles adyacentes $i$ y $j$ se colocan uno en primer plano y el otro en el fondo. El objetivo es encontrar una partición $(A, B)$ del conjunto de píxeles que maximice la siguiente cantidad:\n",
    "\n",
    "$$q(A,B) = \\sum_{i \\in A} a_i + \\sum_{i \\in B} b_i  - \\sum_{i, j \\text{ adyacentes}} p_{ij},$$\n",
    "\n",
    "De hecho, para los píxeles en $A$ (considerados como el primer plano), ganamos $a_i$; para todos los píxeles en $B$ (considerados como el fondo), ganamos $b_i$. En el borde, entre dos píxeles adyacentes $i$ y $j$, perdemos $p_{ij}$. Equivale a minimizar la cantidad\n",
    "\n",
    "$$q'(A,B) = \\sum_{i \\in A} a_i + \\sum_{i \\in B} b_i  + \\sum_{i, j \\text{ adyacentes}} p_{ij},$$\n",
    "\n",
    "porque \n",
    "\n",
    "$$q(A,B) = \\sum_{i \\in A} a_i + \\sum_{i \\in B} b_i - q'(A,B).$$\n",
    "\n",
    "\n",
    "Ahora construimos la red cuyos nodos son el píxel, más una fuente y un sumidero. Conectamos la fuente al píxel $i$ por un arco de peso $a_i$. Conectamos el píxel $i$ al sumidero por un arco de peso $b_i$. Conectamos el píxel $i$ al píxel $j$ con peso $p_{ij}$. Ahora, queda por calcular un corte mínimo en esa red (o equivalentemente un flujo máximo). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Desarrollo de ffmaxflow\n",
    "\n",
    "El código se desarrolló por medio de clases y se utilizó el lenguaje de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Clase del vértice*** \n",
    "\n",
    "La primera clase que se creó es la de vértice. Esta clase sirve para crear los bordes, sin importar si el vértice está en una fuente o sumidero.\n",
    "\n",
    "```\n",
    "class vertex:\n",
    "    \"\"\"\n",
    "    A vertex in a network.\n",
    "    Attributes:\n",
    "        name (string): name or identifier of vertex\n",
    "        source (bool): whether the vertex is a source vertex or not\n",
    "        sink (bool): whether the vertex is a sink vertex or not\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, source=False, sink=False):\n",
    "        self.name = name\n",
    "        self.source = source\n",
    "        self.sink = sink\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Clase de los bordes***\n",
    "\n",
    "La siguiente clase es la de bordes. Esta clase tiene un vértice de entrada, un vértice de salida, la capacidad máxima del flujo, el flujo actual del borde y el borde de retorno que sirve para la gráfica de los residuales.\n",
    "\n",
    "```\n",
    "class edge:\n",
    "    \"\"\"\n",
    "    An edge in a netwokt, going from one vertex to another\n",
    "    Attributes:\n",
    "        start (vertex): the edge comes out of this vertex\n",
    "        end (vertex): the edge arrives at this vertex\n",
    "        capacity (float): edge's maximum flow capacity\n",
    "        flow (float): current flow in the edge\n",
    "        returnEdge (pointer): return edge which is used in the residual graph\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, start, end, capacity):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.capacity = capacity\n",
    "        self.flow = 0\n",
    "        self.returnEdge = None\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Clase red de flujo***\n",
    "\n",
    "La última clase, ```create_flow_network```, tiene dos atributos. Los vértices que son una lista de todos los vértices de la gráfica y la red (network), un diccionario que mapea todos los vértices con todos los bordes que salen del vértice en cuestión. Esta estructura de datos facilita la relación entre vértices y la red que será utilizado en el algoritmo.\n",
    "\n",
    "Las funciones ``` get_source```, ```get_sink```, ```get_vertex``` y ```vertex_in_network``` son utilizadas para evitar duplicar código, en particular ```vertex_in_network``` recibe el nombre del vértice y regresa todo el vértice como objeto de ```create_flow_network```.\n",
    "\n",
    "La función ```create_vertex``` verifica que no existan errores para la cración de vértices y añade los vértices. La función ```create_edge``` verifica que el el vértice inicial y el vértice final estén en la gráfica, además verifica que estos no sean los mismos. Posteriormente crea los bordes y un borde de retorno con capacidad 0, finalmente agrega los bordes y los bordes de retorno al mapa de la red.\n",
    "\n",
    "La función ```get_path``` es una función recursiva que recorre la red de flujo dado un vértice y calcula la capacidad residual por cada borde. La capacidad residual sirve para saber cuánto flujo es posible mandar en un camino en la función ```MaxFlow```. El camino crece hasta llegar al final de la red en donde se termina la recursión.\n",
    "\n",
    "Por último, ```MaxFlow``` llama a ```get_path``` para agregarlos al flujo máximo. Primero encuentra la fuente y el sumidero de la red, posteriormente calcula un camino de aumento. Continúa el método de Ford-Fulkerson y calcula el flujo mientras haya un camino (Mientras exista un camino se puede calcular un flujo). Se agrega el flujo al borde siguiente y se resta el borde residual, posteriormente se calcula otra ruta y se reanuda el proceso. Finalmente se calcula el flujo total que sale de la fuente, que corresponde al flujo máximo de la red.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "class create_flow_network:\n",
    "    \"\"\"\n",
    "    A flow network to which we want to find the maximum flow posible going\n",
    "    from one vertex to another.\n",
    "    Attributes:\n",
    "       vertices (list): lists all of vertices in the graph\n",
    "       network (dictionary): maps every vertex's name to all of the edges\n",
    "                             coming out of the said vertex\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.vertices = []\n",
    "        self.network = {}\n",
    "\n",
    "    def get_source(self):\n",
    "        \"\"\"\n",
    "        Finds the source vertex in the list of vertices in the network.\n",
    "        \"\"\"\n",
    "        for vertex in self.vertices:\n",
    "            if vertex.source == True:\n",
    "                return vertex\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_sink(self):\n",
    "        \"\"\"\n",
    "        Finds the sink vertex in the list of vertices in the flow network.\n",
    "        \"\"\"\n",
    "        for vertex in self.vertices:\n",
    "            if vertex.sink == True:\n",
    "                return vertex\n",
    "\n",
    "        return None\n",
    "\n",
    "    def get_vertex(self, name):\n",
    "        \"\"\"\n",
    "        Takes a vertex name finds it in the lists of vertices of the\n",
    "        object of class create_flow_network.\n",
    "        Args:\n",
    "            name (string): name or identifier of vertex\n",
    "        Returns:\n",
    "            vertex (vertex): object of class vertex corresponding to the\n",
    "                             input vertex name.\n",
    "        \"\"\"\n",
    "        for vertex in self.vertices:\n",
    "            if name == vertex.name:\n",
    "                return vertex\n",
    "\n",
    "    def vertex_in_network(self, name):\n",
    "        \"\"\"\n",
    "        Verifies if a certain vertex is in the list of vertices of the flow\n",
    "        network.\n",
    "        Args:\n",
    "            name (string): name or identifier of vertex.\n",
    "        Returns:\n",
    "            (bool): if the vertex is in the network or not.\n",
    "        \"\"\"\n",
    "        for vertex in self.vertices:\n",
    "            if vertex.name == name:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_edges(self):\n",
    "        \"\"\"\n",
    "        Takes information from the network vertices and gets a list of all\n",
    "        the edges going in and out of this vertices.\n",
    "        Returns:\n",
    "            allEdges (list): list of all vertices in the flow network.\n",
    "        \"\"\"\n",
    "        allEdges = []\n",
    "        for vertex in self.network:\n",
    "            for edge in self.network[vertex]:\n",
    "                allEdges.append(edge)\n",
    "\n",
    "        return allEdges\n",
    "\n",
    "    def create_vertex(self, name, source=False, sink=False):\n",
    "        \"\"\"\n",
    "        Creates and adds a vertex to the network after it checks various\n",
    "        error cases to ensure that the vertex can be added.\n",
    "        Args:\n",
    "            name (string): name or identifier of vertex_in_network\n",
    "            source (bool): whether the vertex to add is source or not\n",
    "            sink (bool): whether the vertex to add is sink or not\n",
    "        Returns:\n",
    "            (string): error message when error arises\n",
    "        \"\"\"\n",
    "        if source == True and sink == True:\n",
    "            return \"El nodo {} no puede ser origen y destino\".format(name)\n",
    "\n",
    "        if self.vertex_in_network(name):\n",
    "            return \"Nodo duplicado\"\n",
    "\n",
    "        if source == True:\n",
    "            if self.get_source() != None:\n",
    "                return \"Ya existe nodo origen\"\n",
    "\n",
    "        if sink == True:\n",
    "            if self.get_sink() != None:\n",
    "                return \"Ya existe nodo destino\"\n",
    "\n",
    "        newVertex = vertex(name, source, sink)\n",
    "        self.vertices.append(newVertex)\n",
    "        self.network[newVertex.name] = []\n",
    "\n",
    "    def create_edge(self, start, end, capacity):\n",
    "        \"\"\"\n",
    "        Creates and adds a new edge to the flow network with capacity of 0\n",
    "        by first checking the start and end vertices of said edge to\n",
    "        verify that the are not the same vertex and that they are both in\n",
    "        the network.\n",
    "        Args:\n",
    "            start (vertex): start vertex of the new edge\n",
    "            end (vertex): end vertex of the new edge\n",
    "            capacity (float): capcity of the new edge\n",
    "        Returns:\n",
    "            (string): error message when error arises\n",
    "        \"\"\"\n",
    "\n",
    "        if self.vertex_in_network(start) == False:\n",
    "            print(\"Nodo origen ya ha sido agregado. \\n El cálculo de flujo máximo continúa con el primer valor asignado al nodo orígen.\")\n",
    "\n",
    "        elif self.vertex_in_network(end) == False:\n",
    "            print(\"Nodo destino ya ha sido agregado. \\n El cálculo del flujo máximo continúa con el primer valor asignado al nodo destino.\")\n",
    "        \n",
    "        elif start == end:\n",
    "            print(\"No se pueden tener bucles. \\n El cálculo de flujo máximo continuará sin tomar en cuenta este arco.\")\n",
    "          \n",
    "        else:\n",
    "            newEdge = edge(start, end, capacity)\n",
    "            returnEdge = edge(end, start, 0)\n",
    "            newEdge.returnEdge = returnEdge\n",
    "            returnEdge.returnEdge = newEdge\n",
    "            vertex = self.get_vertex(start)\n",
    "            self.network[vertex.name].append(newEdge)\n",
    "            returnVertex = self.get_vertex(end)\n",
    "            self.network[returnVertex.name].append(returnEdge)\n",
    "\n",
    "    def get_path(self, start, end, path):\n",
    "        \"\"\"\n",
    "        Recursive function that walks through the network starting at a certain\n",
    "        vertex and calculates residual capacity for each edge it passes then\n",
    "        uses this residual capacity to define how much flow to send along a\n",
    "        given path. Then repeats this process until it reaches the end of the\n",
    "        flow network.\n",
    "        Args:\n",
    "            start (vertex): start vertex of the new edge\n",
    "            end (vertex): end vertex of the new edge\n",
    "            path (list): list of vertices in a path\n",
    "        Returns:\n",
    "            path (list): list of vertices in a path\n",
    "        \"\"\"\n",
    "\n",
    "        if start == end:\n",
    "            return path\n",
    "\n",
    "        for edge in self.network[start]:\n",
    "            residualCapacity = edge.capacity - edge.flow\n",
    "            if residualCapacity > 0 and not (edge, residualCapacity) in path:\n",
    "                result = self.get_path(edge.end, end, path + [(edge, residualCapacity)])\n",
    "                if result != None:\n",
    "                    return result\n",
    "\n",
    "    def MaxFlow(self):\n",
    "        \"\"\"\n",
    "        Follows the path returned by get_path and gets the maximum flow in the\n",
    "        network. This function implements the Ford Fulkerson method and\n",
    "        calculates the flow while the path is not fully walked. It sums this\n",
    "        flow to the fordward edges and substracts it from the reverse edges.\n",
    "        Then, another path is calculated and we repeat the process.\n",
    "        Returns:\n",
    "            (string): error message when an error in the definition of the\n",
    "                      network occurs.\n",
    "            (float): maximum flow through the network\n",
    "        \"\"\"\n",
    "        source = self.get_source()\n",
    "        sink = self.get_sink()\n",
    "\n",
    "        if source == None or sink == None:\n",
    "            return \"La red no tiene nodo origen y/o destino \"\n",
    "\n",
    "        path = self.get_path(source.name, sink.name, [])\n",
    "        while path != None:\n",
    "            flow = min(edge[1] for edge in path)\n",
    "            for edge, res in path:\n",
    "                edge.flow += flow\n",
    "                edge.returnEdge.flow -= flow\n",
    "            path = self.get_path(source.name, sink.name, [])\n",
    "        return sum(edge.flow for edge in self.network[source.name])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Reimplementación de ffmaxflow\n",
    "### 3.1 Robustecimiento\n",
    "#### 3.1.1 Kubernetes\n",
    "\n",
    "Kubernetes es una herramienta desarrollada inicialmente por Google que después fue liberada y donada a [Cloud Native Computing Foundation](https://www.cncf.io/) (CNCF) en 2014. Esta heramienta también es abreviada como *kube* o *k8s* y es una plataforma open source que automatiza las operaciones de los contenedores de Linux. Elimina muchos de los procesos manuales involucrados en la implementación y escalabilidad de las aplicaciones en contenedores. Es decir, kubernetes crea clústers que ejecutan contenedores y ayuda a administrar de forma sencilla y eficiente estos clústeres y sus recursos. .Kubernetes es un orquestador de contenedores que nos ayuda a maximizar el potencial de los contenedores.\n",
    "\n",
    "La principal ventaja de usar Kubernetes es que dispone de una plataforma para programar y ejecutar contenedores en clústeres de máquinas virtuales o físicas. A grandes rasgos, permite implementar una infraestructura basada en contenedores en los entornos de producción, y depender completamente de ella. Como Kubernetes abarca todo lo referido a la automatización de tareas operativas, puede hacer muchas de las cosas que también otras plataformas de aplicaciones o sistemas de gestión le permiten hacer, pero para contenedores.\n",
    "\n",
    "Es importante mencionar que esta herramienta de orquestación requiere de al menos 3 nodos: un máster y otros dos actuan como repositorios de contenedores. La interacción con Kubernetes se hace únicamente con el master, al cual se le dan las órdenes de despliegue, corrida, etc. de nuestros contenedores.\n",
    "\n",
    "**Minikube**\n",
    "\n",
    "Una de las dificultades de utilizar kubernetes es precisamente que al estar pensado para clústeres, necesita de al menos 3 nodos para funcionar. Esto resulta inconveniente para realizar pruebas locales, aquí es donde entra minikube.\n",
    "\n",
    "Minikube también es una herramienta open source, ésta permite el uso de kubernetes en una sóla computadora local, corre un clúster de un sólo nodo dentro de una máquina virtual dentro de la máquina local. Permitiendo así correr demos o experiementos de operaciones de kubernetes sin necesitar de clústeres reales o la instalación completa de kubernetes.\n",
    "\n",
    "En otras palabras, minikube toma la kubernetes y lo comprime de manera que quepa en una laptop conservando las mismas ventajas y funcionalidades. Además, es útil para que usuarios nuevos se familiaricen con los conceptos y configuraciones básicos de kube. \n",
    "\n",
    "#### 3.1.2 Kubeflow\n",
    "Kubeflow es un proyecto construído encima de kubernetes compuesto por varias herramientas y *frameworks* para realizar el desarrollo, despliegue y administración de modelos de aprendizaje de máquina de forma sencilla y escalable. El objetivo de kubeflow es servir como un administrador de inicio a fin para insfraestructura de aprendizaje de máquina de manera simple, portable y escalable.\n",
    "\n",
    "El ciclo de vida de un proyecto de machine learning es muy diverso y consta de varias etapas. Si uno no es cuidadoso en el proceso, estas etapas pueden tener problemas de escalabilidad cuando el servicio se encuentre en la fase de producción. Kubeflow busca evitar el caso anterior tomando en centa el despliegue del proyecto desde sus fases iniciales de desarrollo hasta el propio despliegue a gran escala.\n",
    "\n",
    "Las varias etapas del proyecto son simplificadas y estandarizadas por kubeflow, así como hacer corridas o dar mantenimiento al servicio.\n",
    "\n",
    "![kubeflow](img/kubeflow.png)\n",
    "\n",
    "Otra ventaja de utilizar kubeflow son las kubeflow pipelines que ofrecer soporte para construir y administrar workflows de ML. Una vez que se define una pipeline, esta se puede utilizar como base para múltiples experimentos, donde cada uno puede tener varias corridas. La interfaz de usuario de las pipelines permiten hacer el despliegue y el monitoreo de los experimentos así como visualizar los resultados de cada uno de ellos.\n",
    "\n",
    "\n",
    "\n",
    "**Kale**\n",
    "\n",
    "Kale, acrónimo de Kubeflow Automated pipeLines Engine, simplifica el uso de kubeflow permitiéndole a los usuarios enfocarse completamente en su código en lugar sel setup de las pipelines. Kale permite desplegar un notebook de Jupyter a Kubeflow Pipelines de manera fácil e intuitiva.\n",
    "\n",
    "Kale busca explotar la estructura JSON de los notebooks de de Jupyter para hacer anotaciones tanto en la metadata del notebook como de las celdas. Estas anotaciones permiten (entre otras cosas):\n",
    "1. Asignar el código de cierta celda a un componente del pipeline\n",
    "2. Combinar múltiples celdas en un sólo componente del pipeline\n",
    "3. Definir el orden de ejecución tomando en cuenta las dependencias entre las celdas\n",
    "\n",
    "![kale](img/kale.png)\n",
    "\n",
    "En caso de que se quieran asignar manualmente la metadata del pipeline, existe una extensión de kale para JupyterLab, la cual muestra un panel en el cual al seleccionar una celda se le puede asignar a que paso del pipeline pertenece, así como sus correspondientes dependencias. De esta manera, los usuarios pueden utilizar las funcinalidades de Kubeflow Pipelines sin tener que interactuar con al línea de comandos o insalaciones adicionales\n",
    "\n",
    "#### 3.1.3 Primera reimplementación\n",
    "\n",
    "Una vez desarrollado el paquete de manera básica utilizamos las herramientas de kale y minikube para correr varios experimentos y así detectar valores con los cuales falla nuestro paquete o posibles mejoras a realizar.\n",
    "\n",
    "Para utilizar estas herramientas, y como hemos visto anteriormente que tanto kale como kubernetes estan enfocados a contenedores, fue necesario crear una [imagen de docker](https://hub.docker.com/r/diramtz/pkg2) adicional que contara con estas herramientas, así como con nuestro paquete.\n",
    "\n",
    "Una vez dentro del contenedor, corrimos una gran variedad de experimentos para detectar y corregir flaquezas en nuestro código, entre estos experimentos se tienen:\n",
    "\n",
    "+ **Ejemplo base:** Después de cualquier reimplementación es necesario asegurarse que el paquete sigue resolviendo de manera correcta problemas que resolvía antes.\n",
    "+ **Distintas escalas de valores:** Es importante asegurarnos que nuestro paquete no presente problemas numéricos para las distintas escalas de valores en las capacidades.\n",
    "+ **Varios nodos orígen o destino:** Ahora sólo se guarda el primer nodo orígen o destino definido, no se sobreescriben.\n",
    "+ **El nodo destino también es el nodo orígen:** En este caso el flujo total es de cero por lo que no se realiza el cálculo y se levanta un warning.\n",
    "+ **Bucle:** Los bucles no aportan al flujo total de la red, por lo que no se toman en cuenta para el cálculo de flujo máximo y se levanta un warning.\n",
    "+ **Nodo orígen o destino sin conectar:** Nuevamente, el flujo total es de cero.\n",
    "\n",
    "Para los experimentos elegidos, la gráfica de kale se ve así:\n",
    "\n",
    "            ¿Tenemos screenshot de nuestro experimento?\n",
    "            \n",
    "La reimplementación de robustecimiento se hizo directamente sobre la versión anterior de ffmaxflow alojado en [PyPI](https://pypi.org/project/ffmaxflow/) y las reimplementación están presentes a partir de la versión 0.0.5 y se fue modificando de manera incremental, siendo la versión 0.0.9 la versión estable con todas las reimplementaciones de robustecimiento.\n",
    "\n",
    "**Instalación**\n",
    "\n",
    "            pip install ffmaxflow==0.0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Compilación a C\n",
    "#### 3.2.1 Compilación anticipada o AOT\n",
    "\n",
    "La compilación anticipada (en inglés *ahead-of-time*) es e acto de compilar ucódigo en un lenguaje de programación a un código nativo de máquina que resulta en un archivo binario que puede ejecutarse naivamente en la maquina. En palabras más sencillas, la compilación anticipada transforma un código a un lenguaje de máquina *antes* de su ejecución.\n",
    "\n",
    "Una compilación anticipada crea una librería en la máquina que puede utlizarse de forma instantánea.\n",
    "\n",
    "En la mayoría de los casos, la compiación anticipada resulta en una reducción considerable del entorno de ejecución, de esta manera se ahorra espacio en disco, uso de memoria, batería y tiempo de arranque (en comparación con la compilación *just in time*.\n",
    "\n",
    "Una desvetaja de la compilación anticipada es que no pude realizar suposiciones del código conforme se va corriendo, esta compilación necesita hacer todas las suposiciones posibles al momento de la compilación. Una supocisión importante es el tipo de variables con las que se esta trabajando pues si no se sabe que tipo se usan en un determinado método no se podrá hacer uso de código especializado.\n",
    "\n",
    "**Lenguaje C**\n",
    "\n",
    "C es un lenguaje de programación compilado, que como hemos visto significa que pasa por un compilador para obtener un archivo en lenguaje de máquina. Las principales características de C es su acceso a la memoria a un bajo nivel, conjunto simple de *keywords* y una sintáxis limpia. Todas estas características lo hacen uno de los lenguajes favoritos para desarrollar sistemas operativos.\n",
    "\n",
    "Una de las razones por las que C es tan rápido, además de la compilación anticipada, es que C tiene únicamente lo indispensable para funcionar. Por ejemplo:\n",
    "\n",
    "+ C cuenta con una gran lista de *comportamientos indefinidos*, que significa que se inclina por hacer lo que sea más fácil para la computadora. Por ejemplo:\n",
    "    + Si uno desea accesar el sétimo elemento de un arreglo que tiene sólo 5 elementos en python, nos arrojará un error. C es \"flojo\" en el sentido de qe si existe ese elemento lo lee, y si no existe lee cualquier cosa que se encuentre en el lugar de memoria donde debería de estar.\n",
    "    + Otros lenguajes de programación como python definen un *overflow*, C regresa cualquier número.\n",
    "+ C pone cierta confianza en el programador en el sentido de que piensa que sabe como utilizar y accesar a la memoria por lo que no implementa ningún collector de basura.\n",
    "+ En C no existe el concepto de clases u objetos, se escriben funciones individuales para cada una de las tareas, esto ahorra mucho tiempo en ejecución.\n",
    "\n",
    "#### 3.2.2 Cython\n",
    "\n",
    "Cython es un compilador que toma instrucciones escritas en un lenguaje hídrido entre Python y C y las transforma en un módulo compilado el cual puede ser importado a Python como un módulo cualquiera con un `import`.\n",
    "\n",
    "Cython está diseñado para obtener un rendimiento similar al de C para un código que está escrito mayormente en Python agregando declaraciones tipo-C al código original. Así, con Cython obtenemos la productividad y facilidad de programaciín y lectura de Python junto con el alto rendimiento y velocidad de C.\n",
    "\n",
    "Cython funciona tomando un archivo con extensión `.pyx` escrito en un lenguaje híbrido entre C y Python, lo compila a código de máquina (crea un archivo .c y compila ese archivo con el compilador gcc) y regresa un módulo compilado. El modulo resultante reemplaza las instrucciones en Python que tengan su equivalente en C.\n",
    "\n",
    "![cython](img/cython.png)\n",
    "\n",
    "**Casos en los que conviene utilizar Cython**\n",
    "+ Para un código con muchos for loops con operaciones matemáticas no vectorizadas dentro.\n",
    "+ Para instrucciones donde utilizamos python \"pelón\" sin utilizar paquetes externos.\n",
    "+ Cuando las variables no cambian su tipo\n",
    "\n",
    "#### 3.2.3 Segunda reimplementación\n",
    "\n",
    "Ante de iniciar con la reimplementación realizamos un [perfilamiento](https://github.com/optimizacion-2-2021-1-gh-classroom/practica-2-segunda-parte-diramtz/blob/main/notebooks/perfilamiento.ipynb) de ffmaxflow para así tener una idea del desempeño de nuestro paquete. Durante el perfilamiento descubrimos que el método de `get_path` toma mucho tiempo en relación con los tiempos de las demás líneas, además de la creación de vertices y el cálculo mismo del flujo máximo.\n",
    "\n",
    "En cuanto al perfilamiento de memoria, no encontramos que nuestro paquete estuviera usando memoria excesiva por lo que decidimos optimizar únicamente el tiempo de ejecución y la optimización se realizara con Cython.\n",
    "\n",
    "Con ayuda de las anotaciones amarillas dadas por Cython obtenidas a partir del archivo con extención `.pyx` se identificaron las líneas que \"más Python utilizaban\". Recordemos que mientras más código que se pueda traducir a C se tenga, menor será el tiempo de ejecución. En particular, estas anotaciones se realizan sobre un archivo html, donde las líneas más amarillas representan que se está usando más Python y las blancas, más C.\n",
    "\n",
    "A continuación se presentan 3 de las reimplementaciones que se realizaron, en todos los casos el código original se presenta a la izquierda y la reimplementación a la derecha.\n",
    "\n",
    "**create_vertex**\n",
    "\n",
    "En este método se realizaban varias comparaciones de booleanos para acceder a los ifs, esto provocaba que tuvieramos que accesar a la variable sin saber su tipo y compararlo con un tipo booleano, comparaciónes que implican un tipo desconocido son propias de Python y toman mucho tiempo. En la reimplementación se tomó ventaja de que las variables `source` y `sink` son de hecho booleanos y eliminamos la comparación, haciendo la entrada al if más rápido.\n",
    "\n",
    "Cabe mencionar que también se definieron las variables `source` y `sink` como booleanos en el llamado al método pero por alguna razón esto parecia hacer a las líneas más amarillas.\n",
    "\n",
    "![cython](img/cython_1.png)\n",
    "\n",
    "**MaxFlow**\n",
    "\n",
    "Nuevamente, se hizo uso de que source y sink son booleanos para accesar a los ifs. Además, reemplazamos más comparaciones de tipos desconocidos por las *keywords* `is` y `is not`. Por otra parte, desglosamos la suma del return. Por la cantidad de llamadas a métodos y atributos en `MaxFlow` no había mucho más que pudieramos cambiar pues recordemos que no existen las clases en C.\n",
    "\n",
    "![cython](img/cython_2.png)\n",
    "\n",
    "**get_path**\n",
    "\n",
    "En este caso, separamos los ifs en expresiones más sencillas y aplicamos de nuevo el truco para evitar comparaciones de tipos desconocidos con los `is`, `is not`.\n",
    "\n",
    "![cython](img/cython_3.png)\n",
    "\n",
    "\n",
    "**Instalación**\n",
    "\n",
    "La reimplementación con compilación a C de ffmaxflow se llama ffmaxc y aún no está disponible en PyPI. Sin embargo, puede instalarse sencillamente con los siguientes comandos:\n",
    "\n",
    "            git clone https://github.com/optimizacion-2-2021-1-gh-classroom/practica-2-segunda-parte-diramtz.git\n",
    "            \n",
    "            pip install practica-2-segunda-parte-diramtz/scripts/\n",
    "            \n",
    "O bien, también está disponible una [imagen de docker](https://hub.docker.com/r/diramtz/pkgc) que ya tiene instalado ffmaxc, así como kale, kubeflow y minikube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Aplicación a datos reales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para probar que la implementación de nuestro paquete sea correcta, usaremos datos de este [repositorio](https://github.com/SumitPadhiyar/parallel_ford_fulkerson_gpu/tree/master/dataset), donde hacen una implementación del algoritmo de Ford Fulkerson usando gpu's. En un inicio se intento usar los datos de la [página](http://elib.zib.de/pub/mp-testdata/) propuesta por el profesor pero notamos que al declarar los nodos y los arcos teníamos ciertos errores, por lo que preferimos buscar nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con primera iteración del paquete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importamos el paquete:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmaxflow as ff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definimos la red:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = ff.create_flow_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definimos los nodos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.create_vertex('o', True, False) \n",
    "red.create_vertex('t', False, True) \n",
    "red.create_vertex('a', False, False)\n",
    "red.create_vertex('b', False, False)\n",
    "red.create_vertex('c', False, False)\n",
    "red.create_vertex('d', False, False)\n",
    "red.create_vertex('e', False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definimos los arcos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.create_edge('o', 'a', 5)\n",
    "red.create_edge('o', 'b', 7)\n",
    "red.create_edge('o', 'c', 4)\n",
    "\n",
    "red.create_edge('a', 'b', 1)\n",
    "red.create_edge('a', 'd', 3)\n",
    "\n",
    "red.create_edge('b', 'c', 2)\n",
    "red.create_edge('b', 'd', 4)\n",
    "red.create_edge('b', 'e', 5)\n",
    "\n",
    "red.create_edge('c', 'e', 4)\n",
    "\n",
    "red.create_edge('d', 't', 9)\n",
    "\n",
    "red.create_edge('e', 'd', 1)\n",
    "red.create_edge('e', 't', 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculamos el flujo máximo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red.MaxFlow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparamos resultados con networkx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "G = nx.DiGraph()\n",
    "\n",
    "G.add_edge('o', 'a', capacity=5)\n",
    "G.add_edge('o', 'b', capacity=7)\n",
    "G.add_edge('o', 'c', capacity=4)\n",
    "\n",
    "G.add_edge('a', 'b', capacity=1)\n",
    "G.add_edge('a', 'd', capacity=3)\n",
    "\n",
    "G.add_edge('b', 'c', capacity=2)\n",
    "G.add_edge('b', 'd', capacity=4)\n",
    "G.add_edge('b', 'e', capacity=5)\n",
    "\n",
    "G.add_edge('c', 'e', capacity=4)\n",
    "\n",
    "G.add_edge('d', 't', capacity=9)\n",
    "\n",
    "G.add_edge('e', 'd', capacity=1)\n",
    "G.add_edge('e', 't', capacity=9)\n",
    "\n",
    "flow_value, flow_dict = nx.maximum_flow(G, 'o', 't')\n",
    "flow_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que el resultado coincide con la paquetería *networkx* por lo que nuestra implementación parece ser correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con reimplementación del paquete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos una reimplementación de código usando C, verificaremos que la reimplementación del paquete funciona correctamente con ayuda del ejemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmaxc as ffc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red = ffc.create_flow_network()\n",
    "\n",
    "red.create_vertex('o', True, False) \n",
    "red.create_vertex('t', False, True) \n",
    "red.create_vertex('a', False, False)\n",
    "red.create_vertex('b', False, False)\n",
    "red.create_vertex('c', False, False)\n",
    "red.create_vertex('d', False, False)\n",
    "red.create_vertex('e', False, False)\n",
    "\n",
    "red.create_edge('o', 'a', 5)\n",
    "red.create_edge('o', 'b', 7)\n",
    "red.create_edge('o', 'c', 4)\n",
    "\n",
    "red.create_edge('a', 'b', 1)\n",
    "red.create_edge('a', 'd', 3)\n",
    "\n",
    "red.create_edge('b', 'c', 2)\n",
    "red.create_edge('b', 'd', 4)\n",
    "red.create_edge('b', 'e', 5)\n",
    "\n",
    "red.create_edge('c', 'e', 4)\n",
    "\n",
    "red.create_edge('d', 't', 9)\n",
    "\n",
    "red.create_edge('e', 'd', 1)\n",
    "red.create_edge('e', 't', 9)\n",
    "\n",
    "red.MaxFlow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera obtenemos el mismo resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con datos reales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos descargados de la página previemnete mencionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "df = pd.read_csv(\"data/50v.txt\",  sep = \"\\s+\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este primer ejemplo tenemos 50 nodos distintos y 612 arcos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.values.astype(int)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada uno de los ejemplos que se usaran tienen la siguiente estructura:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 11,  0],\n",
       "       [ 0, 15, 20],\n",
       "       [ 0, 16, 30],\n",
       "       ...,\n",
       "       [48, 37, 26],\n",
       "       [48, 42,  3],\n",
       "       [48, 45, 67]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si leemos por renglón tenemos de que nodo sale el arco, a que nodo llega y la capacidad del mismo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primero resolvemos con primera iteración del paquete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = ff.create_flow_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los nodos con ayuda de un ciclo *for*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nodes = np.unique(np.hstack((df[:,0],df[:,1])))\n",
    "\n",
    "for node in unique_nodes:\n",
    "    if unique_nodes[node] == 0:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), True, False)\n",
    "    \n",
    "    elif unique_nodes[node] == 49:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, True)\n",
    "    \n",
    "    else:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De igual manera con un ciclo *for* definimos los arcos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(df.shape[0]):\n",
    "    red.create_edge('{}'.format(df[row,0]), '{}'.format(df[row,1]), df[row,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(red.MaxFlow())\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiempo de ejcución primera iteración:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5700047016143799"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora comparamos con networkx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    G.add_edge('{}'.format(df[row,0]), '{}'.format(df[row,1]), capacity = df[row,2])\n",
    "    \n",
    "start_time = time.time()  \n",
    "flow_value, flow_dict = nx.maximum_flow(G, '0', '49')\n",
    "end_time = time.time()\n",
    "\n",
    "flow_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el mismo resultado, ahora veamos el tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012277841567993164"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Por último usaremos la reimplementación del paquete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = ffc.create_flow_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290.0\n"
     ]
    }
   ],
   "source": [
    "unique_nodes = np.unique(np.hstack((df[:,0],df[:,1])))\n",
    "\n",
    "for node in unique_nodes:\n",
    "    if unique_nodes[node] == 0:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), True, False)\n",
    "    \n",
    "    elif unique_nodes[node] == 49:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, True)\n",
    "    \n",
    "    else:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, False)\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    red.create_edge('{}'.format(df[row,0]), '{}'.format(df[row,1]), df[row,2])\n",
    "    \n",
    "start_time = time.time()\n",
    "print(red.MaxFlow())\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiempo de ejecución usando la reimplementación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2971045970916748"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro paquete funciona de forma adecuada, observamos que en la reimplementación mejoro el código pues el tiempo de ejecución es menor, sin embargo la paquetería *networkx* es mucho más rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo con datos más grandes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora un ejemplo con 100 nodos y 2475 arcos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Primera iteración del paquete:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2475, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/100v.txt\",  sep = \"\\s+\", header=None)\n",
    "df = df.values.astype(int)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.setrecursionlimit(1500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368\n"
     ]
    }
   ],
   "source": [
    "red = ff.create_flow_network()\n",
    "\n",
    "unique_nodes = np.unique(np.hstack((df[:,0],df[:,1])))\n",
    "\n",
    "for node in unique_nodes:\n",
    "    if unique_nodes[node] == 0:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), True, False)\n",
    "    \n",
    "    elif unique_nodes[node] == 99:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, True)\n",
    "    \n",
    "    else:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, False)\n",
    "        \n",
    "for row in range(df.shape[0]):\n",
    "    red.create_edge('{}'.format(df[row,0]), '{}'.format(df[row,1]), df[row,2])\n",
    "    \n",
    "start_time = time.time()\n",
    "print(red.MaxFlow())\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.389241695404053"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**networkx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    G.add_edge('{}'.format(df[row,0]), '{}'.format(df[row,1]), capacity = df[row,2])\n",
    "    \n",
    "start_time = time.time()  \n",
    "flow_value, flow_dict = nx.maximum_flow(G, '0', '99')\n",
    "end_time = time.time()\n",
    "\n",
    "flow_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019170522689819336"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reimplementación del paquete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = ffc.create_flow_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "368.0\n"
     ]
    }
   ],
   "source": [
    "unique_nodes = np.unique(np.hstack((df[:,0],df[:,1])))\n",
    "\n",
    "for node in unique_nodes:\n",
    "    if unique_nodes[node] == 0:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), True, False)\n",
    "    \n",
    "    elif unique_nodes[node] == 99:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, True)\n",
    "    \n",
    "    else:\n",
    "        red.create_vertex('{}'.format(unique_nodes[node]), False, False)\n",
    "\n",
    "for row in range(df.shape[0]):\n",
    "    red.create_edge('{}'.format(df[row,0]), '{}'.format(df[row,1]), df[row,2])\n",
    "    \n",
    "start_time = time.time()\n",
    "print(red.MaxFlow())\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.470246076583862"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez más comprobamos que el paquete funciona correctamente, que el tiempo de ejecución de la reimplementación es menor que el de la primera iteración y que el networkx tiene una muy buena implementación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe el teorema de **cortadura mínima** el cual consiste en generar una partición de los vértices de una red de flujo en dos conjuntos, de modo que un conjunto incluye la fuente $s$ y el otro incluye el sumidero $t$. Por lo tanto, el flujo máximo está limitado por la capacidad mínima de corte.\n",
    "\n",
    "El corte se define como la suma de las capacidades de los arcos desde el lado de la fuente hasta el lado del sumidero. El flujo máximo tiene que ser igual a la capacidad del corte mínimo.\n",
    "\n",
    "Se puede encontrar un corte mínimo después de realizar un cálculo de flujo máximo utilizando el método Ford Fulkerson. Un posible corte mínimo es el siguiente: el conjunto de todos los vértices que se pueden alcanzar desde s en el gráfico residual (utilizando aristas con capacidad residual positiva), y el conjunto de todos los demás vértices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ford_fulkerson8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una extensión del problema de flujo máxio es el **problema de flujo máximo con costo mínimo** donde cada borde $(u, v)$ también tiene un coeficiente de costo $a_{uv}$ además de su capacidad. Si el flujo a través del borde es $f_{uv}$, entonces el costo total es $a_{uv}* f_{uv}$. Se requiere encontrar un flujo de un tamaño $d$ dado, con el menor costo. En la mayoría de las variantes, los coeficientes de costo pueden ser positivos o negativos. Existen varios algoritmos de tiempo polinomial para este problema.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kale es una herramienta sencilla de utilizar que nos permite familiarizarnos con el flujo de trabajo de kubeflow con kubernetes, además nos permite llevar a cabo experimentos de manera local sin tener que preocuparnos por el momento de levantar clústeres o interactuar con la línea de comandos, nos deja enforcarnos totalmente en nuestro código.\n",
    "\n",
    "La compilación a C con ayuda de Cython es una buena opción para optimizar y agilizar código en Python que no utiliza objetos vectorizados o que no pueden ser vectorizados, cuando se utiliza Python \"pelón\" y cuando las variables no cambian de tipo durante la ejecución del código.\n",
    "\n",
    "No todas las líneas de código tienen su equivalente en C, pues en C no existe el concepto de clase ni de objeto.\n",
    "\n",
    "Cython nos permite tener la comodidad de programar en Python y la velocidad de un módulo compilado anticipadamente. El costo es que se requiere de conocimiento del lenguaje de C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escribir un paquete de cero es una tarea compleja pero deja muchas enseñanzas, te ayuda a entender el problema completamente.\n",
    "\n",
    "Hacer reimplementaciones en el código es bueno, siempre hay algo que mejorar pero hay que tener en cuenta que no siempre vale la pena invertir tanto tiempo.\n",
    "\n",
    "Es difícil competir con paquetes ya implementados que están optimizados pero siempre te puedas dar una idea de estos paquetes.\n",
    "\n",
    "Una forma de mejorar el códigop es intentar paralelizarlo, aprovechando todo el poder computacional de las computadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Referecias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Max Flow Problem Introduction](https://www.geeksforgeeks.org/max-flow-problem-introduction/)\n",
    "+ [Documentación de nuestro paquete](https://optimizacion-2-2021-1-gh-classroom.github.io/practica-2-segunda-parte-diramtz/maxflow.html)\n",
    "+ [Cortadura mínima](https://en.wikipedia.org/wiki/Max-flow_min-cut_theorem)\n",
    "+ [Aplicaciones flujo máximo](https://en.wikipedia.org/wiki/Maximum_flow_problem#Real_world_applications)\n",
    "+ [Coindidencia bipartita](https://en.wikipedia.org/wiki/Introduction_to_Algorithms)\n",
    "+ [Kubernetes' Documentation](https://kubernetes.io/es/docs/concepts/)\n",
    "+ [How to explain Kubernetes in plain English](https://enterprisersproject.com/article/2017/10/how-explain-kubernetes-plain-english)\n",
    "+ [Kubeflow: Starter’s Guide](https://www.globaldots.com/resources/blog/kubeflow-concepts-use-cases-and-starters-guide/)\n",
    "+ [5.3 Compilación a C](https://itam-ds.github.io/analisis-numerico-computo-cientifico/V.optimizacion_de_codigo/5.3/Compilacion_a_C.html#compilacion-aot-y-jit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
